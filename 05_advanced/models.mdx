---
title: "Modelos"
---

### Modelos Disponíveis no Cursor

O Cursor oferece uma variedade de modelos de IA que podem ser usados para diferentes propósitos, desde a geração de código até a revisão e otimização. Cada modelo tem suas próprias características e é projetado para atender a necessidades específicas dos desenvolvedores.

<Frame>
  <img src="/images/advanced/model-toggle.png" />
</Frame>

## Menu Suspenso de Modelos

Abaixo da caixa de entrada de IA, você verá um menu suspenso que permite selecionar o modelo que deseja usar. Por padrão, o Cursor tem esses modelos prontos para uso:

- **GPT-4o**: Um dos modelos mais avançados da OpenAI, conhecido por sua capacidade de entender e gerar texto de forma altamente contextual e precisa.
- **GPT-4**: Oferece um equilíbrio entre desempenho e custo, ideal para tarefas que exigem compreensão profunda do contexto.
- **Claude 3.5 Sonnet**: Um modelo da Anthropic que se destaca por sua capacidade de raciocínio e geração de texto coerente.
- **cursor-small**: O modelo personalizado do Cursor, que é mais rápido e oferece uso ilimitado, ideal para tarefas que não exigem a complexidade dos modelos premium.

### Modelos Apenas para Contexto Longo

No chat de contexto longo, a seleção de modelos é limitada aos modelos que suportam contexto longo:

- **gpt-4o-128k**: Projetado para lidar com grandes volumes de texto, ideal para projetos complexos que exigem análise detalhada.
- **gemini-1.5-flash-500k**: Um modelo da DeepMind que oferece uma janela de contexto extremamente ampla, permitindo a análise de grandes bases de código.
- **claude-3-haiku-200k** e **claude-3-sonnet-200k**: Modelos da Anthropic que combinam capacidade de raciocínio com suporte a contexto longo.

### Como Escolher o Modelo Certo

- **Tarefas Simples**: Use `cursor-small` para tarefas que exigem rapidez e não necessitam de compreensão profunda.
- **Análise Detalhada**: Escolha `GPT-4` ou `Claude 3.5 Sonnet` para tarefas que exigem análise detalhada e compreensão contextual.
- **Projetos Complexos**: Para projetos que envolvem grandes volumes de texto ou código, opte por modelos de contexto longo como `gpt-4o-128k` ou `gemini-1.5-flash-500k`.
